{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b53b9f9f-dc8b-4b27-9aa4-4b304062f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rites\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rites\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\rites\\AppData\\Local\\Temp\\ipykernel_26124\\3964184404.py:34: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dictionary_df = dictionary_df.applymap(lambda x: preprocess(x) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dictionary and test data\n",
    "dictionary_path = 'Dictionary 10.xlsx'\n",
    "test_data_path = 'TEST DATA.csv'\n",
    "\n",
    "# Read dictionary from excel file\n",
    "dictionary_df = pd.read_excel(dictionary_path)\n",
    "\n",
    "# Read test data from csv file\n",
    "test_data_df = pd.read_csv(test_data_path)\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess text: lowercase, remove stopwords, and lemmatize\n",
    "def preprocess(text):\n",
    "    return ' '.join(\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in text.lower().split()\n",
    "        if word not in stop_words\n",
    "    )\n",
    "\n",
    "# Preprocess dictionary words\n",
    "dictionary_df = dictionary_df.applymap(lambda x: preprocess(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Preprocess test data sentences\n",
    "test_data_df['Text'] = test_data_df['Text'].astype(str).apply(preprocess)\n",
    "\n",
    "# Aggregate text by Text-ID\n",
    "aggregated_text_df = test_data_df.groupby('Text-ID')['Text'].apply(' '.join).reset_index()\n",
    "\n",
    "# Initialize output dataframe with the necessary columns\n",
    "output_df = aggregated_text_df[['Text-ID']].copy()\n",
    "\n",
    "# Flatten the dictionary to create a unique vocabulary list\n",
    "vocabulary = dictionary_df.values.flatten()\n",
    "vocabulary = list(set([word for word in vocabulary if pd.notna(word)]))\n",
    "\n",
    "# Initialize TfidfVectorizer with the unique vocabulary\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary, lowercase=False)\n",
    "\n",
    "# Fit and transform the aggregated text data\n",
    "tfidf_matrix = vectorizer.fit_transform(aggregated_text_df['Text'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Merge the TF-IDF scores with the output DataFrame\n",
    "output_df = pd.concat([output_df, tfidf_df], axis=1)\n",
    "\n",
    "# Initialize dictionary count columns with zeros\n",
    "behavior_columns = [\"Security\", \"Conformity\", \"Tradition\", \"Benevolence\", \"Universalism\",\n",
    "                    \"Self-Direction\", \"Stimulation\", \"Hedonism\", \"Achievement\", \"Power\"]\n",
    "\n",
    "# Initialize a DataFrame for counts\n",
    "result_counts = output_df[['Text-ID']].copy()\n",
    "\n",
    "# Function to count matches\n",
    "def count_matches(sentence, words_list):\n",
    "    sentence_words = set(sentence.lower().split())\n",
    "    return sum(word in sentence_words for word in words_list)\n",
    "\n",
    "# Update result_counts with counts based on aggregated text\n",
    "for idx, row in aggregated_text_df.iterrows():\n",
    "    sentence = row['Text']  # Aggregated sentence\n",
    "    for column in behavior_columns:\n",
    "        words_list = dictionary_df[column].dropna().str.lower().tolist()\n",
    "        result_counts.at[idx, column] = count_matches(sentence, words_list)\n",
    "\n",
    "# Binary DataFrame with same structure as result_counts\n",
    "binary_counts = result_counts.copy()\n",
    "\n",
    "# Initialize all count columns to 0 for binary\n",
    "binary_counts[behavior_columns] = 0\n",
    "\n",
    "# Iterate over each row to set the highest value to 1\n",
    "for idx, row in result_counts.iterrows():\n",
    "    highest_category = row[1:].idxmax()  # Find the column with the highest count\n",
    "    binary_counts.at[idx, highest_category] = 1\n",
    "\n",
    "# Save the result_counts (Word Counts) to Excel\n",
    "output_path_counts = 'Word_Counts_t.xlsx'\n",
    "result_counts.to_excel(output_path_counts, index=False, sheet_name='Counts')\n",
    "\n",
    "# Save the binary_counts (Binary DataFrame) to Excel\n",
    "output_path_binary = 'Word_Binary_t.xlsx'\n",
    "binary_counts.to_excel(output_path_binary, index=False, sheet_name='Binary')\n",
    "\n",
    "print(\"Files have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781c3063-2870-4f40-bdb5-e69582bdd265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output saved to Final_tfidf_Output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the provided Excel files\n",
    "expert_binary_path = 'Expert_binary.xlsx'\n",
    "word_binary_path = 'Word_Binary_t.xlsx'\n",
    "\n",
    "expert_binary = pd.read_excel(expert_binary_path)\n",
    "word_binary = pd.read_excel(word_binary_path)\n",
    "\n",
    "# Merge the two dataframes on 'Text-ID'\n",
    "merged_df = pd.merge(expert_binary, word_binary, on='Text-ID', suffixes=('_expert', '_word'))\n",
    "\n",
    "# Create new columns\n",
    "merged_df['Expert Category'] = merged_df.filter(regex='_expert$').idxmax(axis=1).str.replace('_expert', '')\n",
    "merged_df['Word Category'] = merged_df.filter(regex='_word$').idxmax(axis=1).str.replace('_word', '')\n",
    "merged_df['Match'] = merged_df['Expert Category'] == merged_df['Word Category']\n",
    "\n",
    "# Adjust the calculation of match percentage to compare categories rather than words\n",
    "def calculate_category_match_percentage(expert_category, word_category):\n",
    "    return 100.0 if expert_category == word_category else 0.0\n",
    "\n",
    "# Calculate Expert Match % and Word Match %\n",
    "merged_df['Expert Match %'] = merged_df.apply(lambda row: calculate_category_match_percentage(row['Expert Category'], row['Word Category']), axis=1)\n",
    "merged_df['Word Match %'] = merged_df.apply(lambda row: calculate_category_match_percentage(row['Word Category'], row['Expert Category']), axis=1)\n",
    "\n",
    "# Select required columns with correct suffixes\n",
    "expert_columns = [col for col in merged_df.columns if col.endswith('_expert')]\n",
    "word_columns = [col for col in merged_df.columns if col.endswith('_word')]\n",
    "category_columns = [col.replace('_expert', '') for col in expert_columns]\n",
    "\n",
    "# Prepare the final dataframe\n",
    "final_df = merged_df[['Text-ID'] + expert_columns + word_columns + ['Expert Category', 'Word Category', 'Match', 'Expert Match %', 'Word Match %']]\n",
    "\n",
    "# Rename the columns for clarity\n",
    "final_df.columns = ['Text-ID'] + [f'Expert_{col.replace(\"_expert\", \"\")}' for col in expert_columns] + \\\n",
    "                   [f'Word_{col.replace(\"_word\", \"\")}' for col in word_columns] + \\\n",
    "                   ['Expert Category', 'Word Category', 'Match', 'Expert Match %', 'Word Match %']\n",
    "\n",
    "# Save the final dataframe to a new Excel file\n",
    "output_path_final = 'Final_tfidf_Output.xlsx'\n",
    "final_df.to_excel(output_path_final, index=False)\n",
    "\n",
    "print(f\"Final output saved to {output_path_final}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
